{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "968d5474",
      "metadata": {
        "id": "968d5474"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import cv2\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c939cff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c939cff3",
        "outputId": "489a1221-e978-463b-bc69-80b0988e2f90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0bfc3810",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bfc3810",
        "outputId": "14711ab2-75a7-45ed-cb58-e32533a70f80",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d520c392",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d520c392",
        "outputId": "05e2ac8f-975c-4697-9cff-b36bb91489b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e402fda",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8e402fda",
        "outputId": "65dec952-0556-4b82-ffa4-5ff82010ee16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fad8bc64bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "19741f4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "19741f4c",
        "outputId": "200da7c0-c907-4c13-e486-778f8a70550a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"05b3d870-09b8-4ceb-83e9-27f7b3ee650e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"05b3d870-09b8-4ceb-83e9-27f7b3ee650e\")) {                    Plotly.newPlot(                        \"05b3d870-09b8-4ceb-83e9-27f7b3ee650e\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0],[0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0],[0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0],[0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"title\":{\"text\":\"Number : 5\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('05b3d870-09b8-4ceb-83e9-27f7b3ee650e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "px.imshow(X_train[0], title=f\"Number : {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8d72dfe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d72dfe9",
        "outputId": "af7a340d-4b4e-450e-9ff5-32f5fde963b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train / 255\n",
        "print(X_train.shape)\n",
        "X_test = X_test / 255\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9640df11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9640df11",
        "outputId": "0ebbeb83-b1bb-45eb-cef5-878d00f37cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.reshape(len(X_train), 28*28)\n",
        "X_test = X_test.reshape(len(X_test), 28*28)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c29b6c01",
      "metadata": {
        "id": "c29b6c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad478cb-ad2b-4149-869a-76c4488dd464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
              "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
              "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
              "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
              "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
              "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
              "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
              "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
              "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
              "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
              "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
              "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
              "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dc46aff7",
      "metadata": {
        "id": "dc46aff7"
      },
      "outputs": [],
      "source": [
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784, ))\n",
        "input_layer1 = Dense(392, activation=\"relu\")(input_img)\n",
        "input_layer2 = Dense(196, activation=\"relu\")(input_layer1)\n",
        "input_layer3 = Dense(98 , activation=\"relu\")(input_layer2)\n",
        "\n",
        "mid_layer    = Dense(encoding_dim, activation=\"relu\")(input_layer3)\n",
        "\n",
        "output_layer1 = Dense(98 , activation=\"relu\")(mid_layer)\n",
        "output_layer2 = Dense(196, activation=\"relu\")(output_layer1)\n",
        "output_layer3 = Dense(392, activation=\"relu\")(output_layer2)\n",
        "output_layer4 = Dense(784, activation=\"sigmoid\")(output_layer3)\n",
        "\n",
        "auto_encoder = Model(input_img, output_layer4)\n",
        "\n",
        "auto_encoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "89bd8f18",
      "metadata": {
        "id": "89bd8f18"
      },
      "outputs": [],
      "source": [
        "ear_stop = EarlyStopping(monitor=\"loss\", patience=20, verbose=1)\n",
        "red_lr = ReduceLROnPlateau(monitor=\"loss\", patience=10, verbose=1, factor=0.75, min_lr=1e-7)\n",
        "ch_point = ModelCheckpoint(verbose=1, filepath=r\"E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "beefdd4b",
      "metadata": {
        "id": "beefdd4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ccae97-4891-4f49-b386-1fb79ae057f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.1584\n",
            "Epoch 1: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 8s 7ms/step - loss: 0.1580 - val_loss: 0.1166 - lr: 0.0010\n",
            "Epoch 2/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.1089\n",
            "Epoch 2: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1089 - val_loss: 0.1024 - lr: 0.0010\n",
            "Epoch 3/600\n",
            "924/938 [============================>.] - ETA: 0s - loss: 0.0992\n",
            "Epoch 3: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0992 - val_loss: 0.0957 - lr: 0.0010\n",
            "Epoch 4/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0938\n",
            "Epoch 4: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0938 - val_loss: 0.0924 - lr: 0.0010\n",
            "Epoch 5/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0906\n",
            "Epoch 5: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0906 - val_loss: 0.0890 - lr: 0.0010\n",
            "Epoch 6/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0883\n",
            "Epoch 6: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0883 - val_loss: 0.0872 - lr: 0.0010\n",
            "Epoch 7/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0867\n",
            "Epoch 7: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0867 - val_loss: 0.0867 - lr: 0.0010\n",
            "Epoch 8/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0852\n",
            "Epoch 8: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0852 - val_loss: 0.0843 - lr: 0.0010\n",
            "Epoch 9/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0842\n",
            "Epoch 9: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0842 - val_loss: 0.0842 - lr: 0.0010\n",
            "Epoch 10/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0832\n",
            "Epoch 10: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0832 - val_loss: 0.0830 - lr: 0.0010\n",
            "Epoch 11/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0825\n",
            "Epoch 11: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0825 - val_loss: 0.0836 - lr: 0.0010\n",
            "Epoch 12/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0821\n",
            "Epoch 12: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0821 - val_loss: 0.0815 - lr: 0.0010\n",
            "Epoch 13/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0814\n",
            "Epoch 13: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0814 - val_loss: 0.0820 - lr: 0.0010\n",
            "Epoch 14/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0810\n",
            "Epoch 14: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0810 - val_loss: 0.0820 - lr: 0.0010\n",
            "Epoch 15/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0807\n",
            "Epoch 15: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0807 - val_loss: 0.0814 - lr: 0.0010\n",
            "Epoch 16/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0804\n",
            "Epoch 16: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0804 - val_loss: 0.0817 - lr: 0.0010\n",
            "Epoch 17/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0801\n",
            "Epoch 17: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0801 - val_loss: 0.0806 - lr: 0.0010\n",
            "Epoch 18/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0799\n",
            "Epoch 18: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0799 - val_loss: 0.0800 - lr: 0.0010\n",
            "Epoch 19/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0796\n",
            "Epoch 19: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0796 - val_loss: 0.0809 - lr: 0.0010\n",
            "Epoch 20/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0794\n",
            "Epoch 20: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0794 - val_loss: 0.0802 - lr: 0.0010\n",
            "Epoch 21/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0792\n",
            "Epoch 21: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0792 - val_loss: 0.0801 - lr: 0.0010\n",
            "Epoch 22/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0791\n",
            "Epoch 22: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0791 - val_loss: 0.0801 - lr: 0.0010\n",
            "Epoch 23/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0789\n",
            "Epoch 23: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0789 - val_loss: 0.0799 - lr: 0.0010\n",
            "Epoch 24/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0787\n",
            "Epoch 24: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0787 - val_loss: 0.0799 - lr: 0.0010\n",
            "Epoch 25/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0785\n",
            "Epoch 25: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0786 - val_loss: 0.0793 - lr: 0.0010\n",
            "Epoch 26/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0785\n",
            "Epoch 26: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0785 - val_loss: 0.0789 - lr: 0.0010\n",
            "Epoch 27/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0784\n",
            "Epoch 27: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0784 - val_loss: 0.0794 - lr: 0.0010\n",
            "Epoch 28/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0782\n",
            "Epoch 28: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0782 - val_loss: 0.0795 - lr: 0.0010\n",
            "Epoch 29/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0781\n",
            "Epoch 29: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0781 - val_loss: 0.0790 - lr: 0.0010\n",
            "Epoch 30/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0780\n",
            "Epoch 30: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0780 - val_loss: 0.0790 - lr: 0.0010\n",
            "Epoch 31/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0779\n",
            "Epoch 31: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0779 - val_loss: 0.0787 - lr: 0.0010\n",
            "Epoch 32/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0779\n",
            "Epoch 32: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0779 - val_loss: 0.0791 - lr: 0.0010\n",
            "Epoch 33/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0778\n",
            "Epoch 33: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0777 - val_loss: 0.0792 - lr: 0.0010\n",
            "Epoch 34/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0776\n",
            "Epoch 34: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0777 - val_loss: 0.0791 - lr: 0.0010\n",
            "Epoch 35/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0776\n",
            "Epoch 35: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0776 - val_loss: 0.0792 - lr: 0.0010\n",
            "Epoch 36/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0775\n",
            "Epoch 36: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0775 - val_loss: 0.0790 - lr: 0.0010\n",
            "Epoch 37/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0774\n",
            "Epoch 37: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0774 - val_loss: 0.0788 - lr: 0.0010\n",
            "Epoch 38/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0773\n",
            "Epoch 38: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0773 - val_loss: 0.0788 - lr: 0.0010\n",
            "Epoch 39/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0773\n",
            "Epoch 39: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0773 - val_loss: 0.0785 - lr: 0.0010\n",
            "Epoch 40/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0772\n",
            "Epoch 40: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0772 - val_loss: 0.0786 - lr: 0.0010\n",
            "Epoch 41/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0771\n",
            "Epoch 41: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0771 - val_loss: 0.0784 - lr: 0.0010\n",
            "Epoch 42/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0771\n",
            "Epoch 42: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0771 - val_loss: 0.0786 - lr: 0.0010\n",
            "Epoch 43/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0770\n",
            "Epoch 43: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0770 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 44/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0769\n",
            "Epoch 44: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0769 - val_loss: 0.0788 - lr: 0.0010\n",
            "Epoch 45/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0769\n",
            "Epoch 45: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0769 - val_loss: 0.0785 - lr: 0.0010\n",
            "Epoch 46/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0768\n",
            "Epoch 46: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0769 - val_loss: 0.0783 - lr: 0.0010\n",
            "Epoch 47/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0768\n",
            "Epoch 47: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0768 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 48/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0767\n",
            "Epoch 48: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0767 - val_loss: 0.0785 - lr: 0.0010\n",
            "Epoch 49/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0767\n",
            "Epoch 49: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0767 - val_loss: 0.0783 - lr: 0.0010\n",
            "Epoch 50/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0767\n",
            "Epoch 50: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0767 - val_loss: 0.0777 - lr: 0.0010\n",
            "Epoch 51/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0766\n",
            "Epoch 51: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0765 - val_loss: 0.0777 - lr: 0.0010\n",
            "Epoch 52/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0765\n",
            "Epoch 52: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0765 - val_loss: 0.0780 - lr: 0.0010\n",
            "Epoch 53/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0765\n",
            "Epoch 53: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0765 - val_loss: 0.0776 - lr: 0.0010\n",
            "Epoch 54/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0765\n",
            "Epoch 54: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0765 - val_loss: 0.0782 - lr: 0.0010\n",
            "Epoch 55/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0764\n",
            "Epoch 55: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0764 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 56/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0763\n",
            "Epoch 56: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0763 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 57/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0763\n",
            "Epoch 57: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0763 - val_loss: 0.0780 - lr: 0.0010\n",
            "Epoch 58/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0763\n",
            "Epoch 58: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0763 - val_loss: 0.0776 - lr: 0.0010\n",
            "Epoch 59/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0762\n",
            "Epoch 59: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0763 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 60/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0763\n",
            "Epoch 60: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0763 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 61/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0762\n",
            "Epoch 61: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0762 - val_loss: 0.0782 - lr: 0.0010\n",
            "Epoch 62/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0761\n",
            "Epoch 62: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0761 - val_loss: 0.0781 - lr: 0.0010\n",
            "Epoch 63/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0761\n",
            "Epoch 63: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0761 - val_loss: 0.0783 - lr: 0.0010\n",
            "Epoch 64/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0761\n",
            "Epoch 64: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0761 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 65/600\n",
            "924/938 [============================>.] - ETA: 0s - loss: 0.0759\n",
            "Epoch 65: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0760 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 66/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0760\n",
            "Epoch 66: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0760 - val_loss: 0.0783 - lr: 0.0010\n",
            "Epoch 67/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0760\n",
            "Epoch 67: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0760 - val_loss: 0.0777 - lr: 0.0010\n",
            "Epoch 68/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0759\n",
            "Epoch 68: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0759 - val_loss: 0.0777 - lr: 0.0010\n",
            "Epoch 69/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0759\n",
            "Epoch 69: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0759 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 70/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0759\n",
            "Epoch 70: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0759 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 71/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0758\n",
            "Epoch 71: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0758 - val_loss: 0.0780 - lr: 0.0010\n",
            "Epoch 72/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0758\n",
            "Epoch 72: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0758 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 73/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0757\n",
            "Epoch 73: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0757 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 74/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0757\n",
            "Epoch 74: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0757 - val_loss: 0.0778 - lr: 0.0010\n",
            "Epoch 75/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0757\n",
            "Epoch 75: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0757 - val_loss: 0.0777 - lr: 0.0010\n",
            "Epoch 76/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0757\n",
            "Epoch 76: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0757 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 77/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0757\n",
            "Epoch 77: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0757 - val_loss: 0.0779 - lr: 0.0010\n",
            "Epoch 78/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0756\n",
            "Epoch 78: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0756 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 79/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0756\n",
            "Epoch 79: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0756 - val_loss: 0.0778 - lr: 0.0010\n",
            "Epoch 80/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0756\n",
            "Epoch 80: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0756 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 81/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0755\n",
            "Epoch 81: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0755 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 82/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0755\n",
            "Epoch 82: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0755 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 83/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0755\n",
            "Epoch 83: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0755 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 84/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0755\n",
            "Epoch 84: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0755 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 85/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 85: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - val_loss: 0.0778 - lr: 0.0010\n",
            "Epoch 86/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 86: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - val_loss: 0.0776 - lr: 0.0010\n",
            "Epoch 87/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 87: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0754 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 88/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 88: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 89/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0753\n",
            "Epoch 89: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0753 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 90/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 90: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 91/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0754\n",
            "Epoch 91: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 92/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0753\n",
            "Epoch 92: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0753 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 93/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0753\n",
            "Epoch 93: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0753 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 94/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0752\n",
            "Epoch 94: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0752 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 95/600\n",
            "924/938 [============================>.] - ETA: 0s - loss: 0.0752\n",
            "Epoch 95: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0752 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 96/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0753\n",
            "Epoch 96: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0753 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 97/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0752\n",
            "Epoch 97: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0752 - val_loss: 0.0778 - lr: 0.0010\n",
            "Epoch 98/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0751\n",
            "Epoch 98: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0752 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 99/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0752\n",
            "Epoch 99: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0752 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 100/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0752\n",
            "Epoch 100: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0752 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 101/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0751\n",
            "Epoch 101: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0751 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 102/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0751\n",
            "Epoch 102: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0751 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 103/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0751\n",
            "Epoch 103: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0751 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 104/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0751\n",
            "Epoch 104: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0751 - val_loss: 0.0775 - lr: 0.0010\n",
            "Epoch 105/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0750\n",
            "Epoch 105: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0750 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 106/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0750\n",
            "Epoch 106: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0750 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 107/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0750\n",
            "Epoch 107: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0750 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 108/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0750\n",
            "Epoch 108: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0750 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 109/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 109: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0749 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 110/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0750\n",
            "Epoch 110: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0750 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 111/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 111: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0749 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 112/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0750\n",
            "Epoch 112: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0750 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 113/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0749\n",
            "Epoch 113: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0749 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 114/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 114: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0749 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 115/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 115: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0749 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 116/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0749\n",
            "Epoch 116: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0749 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 117/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0749\n",
            "Epoch 117: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0748 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 118/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0748\n",
            "Epoch 118: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0748 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 119/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0748\n",
            "Epoch 119: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0748 - val_loss: 0.0772 - lr: 0.0010\n",
            "Epoch 120/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0748\n",
            "Epoch 120: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0748 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 121/600\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0748\n",
            "Epoch 121: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0748 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 122/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0748\n",
            "Epoch 122: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0748 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 123/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 123: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0747 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 124/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 124: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0747 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 125/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 125: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0747 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 126/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 126: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0747 - val_loss: 0.0768 - lr: 0.0010\n",
            "Epoch 127/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0747\n",
            "Epoch 127: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0747 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 128/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 128: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0747 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 129/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0747\n",
            "Epoch 129: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0747 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 130/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 130: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0746 - val_loss: 0.0774 - lr: 0.0010\n",
            "Epoch 131/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 131: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0746 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 132/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 132: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0746 - val_loss: 0.0771 - lr: 0.0010\n",
            "Epoch 133/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 133: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0746 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 134/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 134: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0746 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 135/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 135: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0746 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 136/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0746\n",
            "Epoch 136: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0746 - val_loss: 0.0773 - lr: 0.0010\n",
            "Epoch 137/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 137: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0746 - val_loss: 0.0767 - lr: 0.0010\n",
            "Epoch 138/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 138: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0746 - val_loss: 0.0770 - lr: 0.0010\n",
            "Epoch 139/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0746\n",
            "Epoch 139: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0746 - val_loss: 0.0765 - lr: 0.0010\n",
            "Epoch 140/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0745\n",
            "Epoch 140: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0745 - val_loss: 0.0766 - lr: 0.0010\n",
            "Epoch 141/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0745\n",
            "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
            "\n",
            "Epoch 141: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0745 - val_loss: 0.0769 - lr: 0.0010\n",
            "Epoch 142/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 142: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0737 - val_loss: 0.0760 - lr: 7.5000e-04\n",
            "Epoch 143/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0738\n",
            "Epoch 143: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0738 - val_loss: 0.0761 - lr: 7.5000e-04\n",
            "Epoch 144/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0738\n",
            "Epoch 144: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0738 - val_loss: 0.0762 - lr: 7.5000e-04\n",
            "Epoch 145/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0738\n",
            "Epoch 145: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0738 - val_loss: 0.0763 - lr: 7.5000e-04\n",
            "Epoch 146/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 146: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0737 - val_loss: 0.0763 - lr: 7.5000e-04\n",
            "Epoch 147/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0738\n",
            "Epoch 147: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0738 - val_loss: 0.0762 - lr: 7.5000e-04\n",
            "Epoch 148/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0738\n",
            "Epoch 148: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0738 - val_loss: 0.0759 - lr: 7.5000e-04\n",
            "Epoch 149/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 149: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0737 - val_loss: 0.0764 - lr: 7.5000e-04\n",
            "Epoch 150/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 150: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0737 - val_loss: 0.0763 - lr: 7.5000e-04\n",
            "Epoch 151/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 151: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0737 - val_loss: 0.0761 - lr: 7.5000e-04\n",
            "Epoch 152/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0737\n",
            "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
            "\n",
            "Epoch 152: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0737 - val_loss: 0.0762 - lr: 7.5000e-04\n",
            "Epoch 153/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 153: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0732 - val_loss: 0.0757 - lr: 5.6250e-04\n",
            "Epoch 154/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 154: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0732 - val_loss: 0.0757 - lr: 5.6250e-04\n",
            "Epoch 155/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 155: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0732 - val_loss: 0.0758 - lr: 5.6250e-04\n",
            "Epoch 156/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 156: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0732 - val_loss: 0.0758 - lr: 5.6250e-04\n",
            "Epoch 157/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 157: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0732 - val_loss: 0.0759 - lr: 5.6250e-04\n",
            "Epoch 158/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 158: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0732 - val_loss: 0.0759 - lr: 5.6250e-04\n",
            "Epoch 159/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 159: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0732 - val_loss: 0.0758 - lr: 5.6250e-04\n",
            "Epoch 160/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0732\n",
            "Epoch 160: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0732 - val_loss: 0.0759 - lr: 5.6250e-04\n",
            "Epoch 161/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0731\n",
            "Epoch 161: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0731 - val_loss: 0.0757 - lr: 5.6250e-04\n",
            "Epoch 162/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0731\n",
            "Epoch 162: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0731 - val_loss: 0.0757 - lr: 5.6250e-04\n",
            "Epoch 163/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0731\n",
            "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
            "\n",
            "Epoch 163: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0731 - val_loss: 0.0758 - lr: 5.6250e-04\n",
            "Epoch 164/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 164: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0727 - val_loss: 0.0753 - lr: 4.2187e-04\n",
            "Epoch 165/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 165: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0727 - val_loss: 0.0754 - lr: 4.2187e-04\n",
            "Epoch 166/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0728\n",
            "Epoch 166: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0728 - val_loss: 0.0756 - lr: 4.2187e-04\n",
            "Epoch 167/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 167: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0727 - val_loss: 0.0756 - lr: 4.2187e-04\n",
            "Epoch 168/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 168: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0727 - val_loss: 0.0756 - lr: 4.2187e-04\n",
            "Epoch 169/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 169: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0727 - val_loss: 0.0755 - lr: 4.2187e-04\n",
            "Epoch 170/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 170: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0727 - val_loss: 0.0754 - lr: 4.2187e-04\n",
            "Epoch 171/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 171: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0727 - val_loss: 0.0756 - lr: 4.2187e-04\n",
            "Epoch 172/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 172: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0727 - val_loss: 0.0754 - lr: 4.2187e-04\n",
            "Epoch 173/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 173: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0727 - val_loss: 0.0756 - lr: 4.2187e-04\n",
            "Epoch 174/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0727\n",
            "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
            "\n",
            "Epoch 174: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0727 - val_loss: 0.0755 - lr: 4.2187e-04\n",
            "Epoch 175/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 175: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0724 - val_loss: 0.0752 - lr: 3.1641e-04\n",
            "Epoch 176/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 176: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0724 - val_loss: 0.0752 - lr: 3.1641e-04\n",
            "Epoch 177/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 177: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0752 - lr: 3.1641e-04\n",
            "Epoch 178/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 178: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0753 - lr: 3.1641e-04\n",
            "Epoch 179/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 179: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0754 - lr: 3.1641e-04\n",
            "Epoch 180/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 180: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0724 - val_loss: 0.0754 - lr: 3.1641e-04\n",
            "Epoch 181/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 181: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0724 - val_loss: 0.0754 - lr: 3.1641e-04\n",
            "Epoch 182/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 182: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0753 - lr: 3.1641e-04\n",
            "Epoch 183/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 183: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0724 - val_loss: 0.0755 - lr: 3.1641e-04\n",
            "Epoch 184/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 184: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0754 - lr: 3.1641e-04\n",
            "Epoch 185/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0724\n",
            "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
            "\n",
            "Epoch 185: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0754 - lr: 3.1641e-04\n",
            "Epoch 186/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0722\n",
            "Epoch 186: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0722 - val_loss: 0.0753 - lr: 2.3730e-04\n",
            "Epoch 187/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0722\n",
            "Epoch 187: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0722 - val_loss: 0.0751 - lr: 2.3730e-04\n",
            "Epoch 188/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0722\n",
            "Epoch 188: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0722 - val_loss: 0.0754 - lr: 2.3730e-04\n",
            "Epoch 189/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0722\n",
            "Epoch 189: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0722 - val_loss: 0.0752 - lr: 2.3730e-04\n",
            "Epoch 190/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0721\n",
            "Epoch 190: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0722 - val_loss: 0.0754 - lr: 2.3730e-04\n",
            "Epoch 191/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0722\n",
            "Epoch 191: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0722 - val_loss: 0.0753 - lr: 2.3730e-04\n",
            "Epoch 192/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0721\n",
            "Epoch 192: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0721 - val_loss: 0.0752 - lr: 2.3730e-04\n",
            "Epoch 193/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0721\n",
            "Epoch 193: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0721 - val_loss: 0.0753 - lr: 2.3730e-04\n",
            "Epoch 194/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0721\n",
            "Epoch 194: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0721 - val_loss: 0.0752 - lr: 2.3730e-04\n",
            "Epoch 195/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0721\n",
            "Epoch 195: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0721 - val_loss: 0.0752 - lr: 2.3730e-04\n",
            "Epoch 196/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0721\n",
            "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
            "\n",
            "Epoch 196: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0721 - val_loss: 0.0754 - lr: 2.3730e-04\n",
            "Epoch 197/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 197: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0720 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 198/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 198: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0720 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 199/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 199: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0720 - val_loss: 0.0753 - lr: 1.7798e-04\n",
            "Epoch 200/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 200: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0720 - val_loss: 0.0752 - lr: 1.7798e-04\n",
            "Epoch 201/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 201: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0720 - val_loss: 0.0752 - lr: 1.7798e-04\n",
            "Epoch 202/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 202: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0720 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 203/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 203: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0720 - val_loss: 0.0752 - lr: 1.7798e-04\n",
            "Epoch 204/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 204: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0720 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 205/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0720\n",
            "Epoch 205: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0720 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 206/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0719\n",
            "Epoch 206: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0719 - val_loss: 0.0752 - lr: 1.7798e-04\n",
            "Epoch 207/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0719\n",
            "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
            "\n",
            "Epoch 207: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0719 - val_loss: 0.0751 - lr: 1.7798e-04\n",
            "Epoch 208/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 208: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0718 - val_loss: 0.0752 - lr: 1.3348e-04\n",
            "Epoch 209/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0718\n",
            "Epoch 209: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 210/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 210: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 211/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 211: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 212/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 212: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 213/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 213: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 214/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0718\n",
            "Epoch 214: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 215/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 215: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - val_loss: 0.0752 - lr: 1.3348e-04\n",
            "Epoch 216/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 216: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 217/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 217: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 218/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0718\n",
            "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.00010011290578404441.\n",
            "\n",
            "Epoch 218: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0718 - val_loss: 0.0751 - lr: 1.3348e-04\n",
            "Epoch 219/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 219: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - val_loss: 0.0750 - lr: 1.0011e-04\n",
            "Epoch 220/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 220: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0750 - lr: 1.0011e-04\n",
            "Epoch 221/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 221: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 222/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 222: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0717 - val_loss: 0.0750 - lr: 1.0011e-04\n",
            "Epoch 223/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 223: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 224/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 224: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 225/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 225: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 226/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 226: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 227/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 227: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 228/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0717\n",
            "Epoch 228: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 229/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0717\n",
            "Epoch 229: ReduceLROnPlateau reducing learning rate to 7.508467933803331e-05.\n",
            "\n",
            "Epoch 229: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0751 - lr: 1.0011e-04\n",
            "Epoch 230/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 230: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 231/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 231: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 232/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 232: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - val_loss: 0.0751 - lr: 7.5085e-05\n",
            "Epoch 233/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 233: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 234/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 234: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0751 - lr: 7.5085e-05\n",
            "Epoch 235/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0716\n",
            "Epoch 235: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 236/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 236: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - val_loss: 0.0751 - lr: 7.5085e-05\n",
            "Epoch 237/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 237: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 238/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 238: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 7.5085e-05\n",
            "Epoch 239/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 239: ReduceLROnPlateau reducing learning rate to 5.6313510867767036e-05.\n",
            "\n",
            "Epoch 239: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0751 - lr: 7.5085e-05\n",
            "Epoch 240/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 240: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 241/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 241: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 242/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 242: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0751 - lr: 5.6314e-05\n",
            "Epoch 243/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 243: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 244/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 244: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 245/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 245: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 246/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 246: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 247/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 247: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 248/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 248: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 249/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0716\n",
            "Epoch 249: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 250/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0716\n",
            "Epoch 250: ReduceLROnPlateau reducing learning rate to 4.223513315082528e-05.\n",
            "\n",
            "Epoch 250: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0716 - val_loss: 0.0750 - lr: 5.6314e-05\n",
            "Epoch 251/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 251: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 252/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 252: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 253/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 253: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 254/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0715\n",
            "Epoch 254: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 255/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 255: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 256/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 256: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 257/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 257: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 258/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0715\n",
            "Epoch 258: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 259/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0715\n",
            "Epoch 259: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 260/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 260: ReduceLROnPlateau reducing learning rate to 3.167634986311896e-05.\n",
            "\n",
            "Epoch 260: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 4.2235e-05\n",
            "Epoch 261/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 261: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 262/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 262: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 263/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 263: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 264/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 264: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 265/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 265: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 266/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 266: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 267/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 267: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 268/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 268: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 269/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 269: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 270/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 270: ReduceLROnPlateau reducing learning rate to 2.3757263079460245e-05.\n",
            "\n",
            "Epoch 270: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0750 - lr: 3.1676e-05\n",
            "Epoch 271/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 271: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 272/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 272: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 273/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 273: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 274/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0715\n",
            "Epoch 274: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 275/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 275: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 276/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 276: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 277/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 277: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 278/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 278: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 279/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 279: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 280/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 280: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 281/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 281: ReduceLROnPlateau reducing learning rate to 1.781794799171621e-05.\n",
            "\n",
            "Epoch 281: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3757e-05\n",
            "Epoch 282/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 282: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 283/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 283: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 284/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 284: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 285/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 285: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 286/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 286: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 287/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 287: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 288/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 288: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 289/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 289: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 290/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 290: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 291/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 291: ReduceLROnPlateau reducing learning rate to 1.3363460311666131e-05.\n",
            "\n",
            "Epoch 291: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7818e-05\n",
            "Epoch 292/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 292: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 293/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 293: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 294/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 294: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 295/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 295: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 296/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 296: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 297/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 297: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 298/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 298: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 299/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 299: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 300/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 300: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 301/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 301: ReduceLROnPlateau reducing learning rate to 1.0022595233749598e-05.\n",
            "\n",
            "Epoch 301: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3363e-05\n",
            "Epoch 302/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 302: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 303/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 303: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 304/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 304: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 305/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 305: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 306/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 306: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 307/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 307: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 308/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 308: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 309/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 309: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 310/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 310: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 311/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 311: ReduceLROnPlateau reducing learning rate to 7.516946425312199e-06.\n",
            "\n",
            "Epoch 311: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.0023e-05\n",
            "Epoch 312/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 312: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 313/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 313: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 314/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 314: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 315/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 315: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 316/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 316: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 317/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 317: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 318/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 318: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 319/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 319: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 320/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 320: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 321/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 321: ReduceLROnPlateau reducing learning rate to 5.637709818984149e-06.\n",
            "\n",
            "Epoch 321: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 7.5169e-06\n",
            "Epoch 322/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 322: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 323/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 323: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 324/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 324: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 325/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 325: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 326/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 326: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 327/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 327: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 328/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 328: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 329/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 329: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 330/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 330: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 331/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 331: ReduceLROnPlateau reducing learning rate to 4.228282364238112e-06.\n",
            "\n",
            "Epoch 331: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 5.6377e-06\n",
            "Epoch 332/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 332: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 333/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 333: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 334/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 334: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 335/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 335: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 336/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 336: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 337/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 337: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 338/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 338: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 339/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 339: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 340/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 340: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 341/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 341: ReduceLROnPlateau reducing learning rate to 3.1712116879134555e-06.\n",
            "\n",
            "Epoch 341: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 4.2283e-06\n",
            "Epoch 342/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 342: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 343/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 343: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 344/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 344: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 345/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 345: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 346/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 346: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 347/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 347: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 348/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 348: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 349/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 349: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 350/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 350: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 351/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 351: ReduceLROnPlateau reducing learning rate to 2.3784086806699634e-06.\n",
            "\n",
            "Epoch 351: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 3.1712e-06\n",
            "Epoch 352/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 352: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 353/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 353: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 354/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 354: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 355/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 355: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 356/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 356: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 357/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 357: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 358/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 358: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 359/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 359: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 360/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 360: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 361/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 361: ReduceLROnPlateau reducing learning rate to 1.7838065105024725e-06.\n",
            "\n",
            "Epoch 361: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 2.3784e-06\n",
            "Epoch 362/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 362: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 363/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 363: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 364/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 364: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 365/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 365: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 366/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 366: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 367/600\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 367: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 368/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 368: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 369/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 369: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 370/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 370: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 371/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 371: ReduceLROnPlateau reducing learning rate to 1.3378548828768544e-06.\n",
            "\n",
            "Epoch 371: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.7838e-06\n",
            "Epoch 372/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 372: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 373/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 373: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 374/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 374: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 375/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 375: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0714 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 376/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 376: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 377/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 377: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 378/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 378: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 379/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 379: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 380/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 380: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 381/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 381: ReduceLROnPlateau reducing learning rate to 1.0033911621576408e-06.\n",
            "\n",
            "Epoch 381: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3379e-06\n",
            "Epoch 382/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 382: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 383/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 383: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 384/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 384: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 385/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 385: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 386/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 386: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 387/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 387: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 388/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 388: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 389/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 389: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 390/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 390: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 391/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 391: ReduceLROnPlateau reducing learning rate to 7.525433716182306e-07.\n",
            "\n",
            "Epoch 391: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0034e-06\n",
            "Epoch 392/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 392: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 393/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 393: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 394/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 394: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 395/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 395: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 396/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 396: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 397/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 397: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 398/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 398: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 399/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 399: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 400/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 400: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 401/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 401: ReduceLROnPlateau reducing learning rate to 5.644075287136729e-07.\n",
            "\n",
            "Epoch 401: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 7.5254e-07\n",
            "Epoch 402/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 402: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 403/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 403: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 404/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 404: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 405/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 405: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 406/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 406: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 407/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 407: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 408/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 408: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 409/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 409: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 410/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 410: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 411/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 411: ReduceLROnPlateau reducing learning rate to 4.2330563587711367e-07.\n",
            "\n",
            "Epoch 411: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 5.6441e-07\n",
            "Epoch 412/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 412: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 413/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 413: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 414/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 414: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 415/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 415: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 416/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 416: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 417/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 417: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 418/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 418: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 419/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 419: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 420/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 420: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 421/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 421: ReduceLROnPlateau reducing learning rate to 3.1747922690783525e-07.\n",
            "\n",
            "Epoch 421: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 4.2331e-07\n",
            "Epoch 422/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 422: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 423/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 423: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 424/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 424: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 425/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 425: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 426/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 426: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 427/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 427: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 428/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 428: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 429/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 429: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 430/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 430: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 431/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 431: ReduceLROnPlateau reducing learning rate to 2.3810941485180592e-07.\n",
            "\n",
            "Epoch 431: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 3.1748e-07\n",
            "Epoch 432/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 432: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 433/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 433: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 434/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 434: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 435/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 435: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 436/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 436: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 437/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 437: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 438/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 438: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 439/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 439: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 440/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 440: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 441/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 441: ReduceLROnPlateau reducing learning rate to 1.7858205580978392e-07.\n",
            "\n",
            "Epoch 441: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 2.3811e-07\n",
            "Epoch 442/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 442: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 443/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 443: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 444/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 444: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 445/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 445: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 446/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 446: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 447/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 447: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 448/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 448: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 449/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 449: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 450/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 450: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 451/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 451: ReduceLROnPlateau reducing learning rate to 1.3393654185733794e-07.\n",
            "\n",
            "Epoch 451: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.7858e-07\n",
            "Epoch 452/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 452: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 453/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 453: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 454/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 454: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 455/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 455: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 456/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 456: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 457/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 457: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 458/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 458: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 459/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 459: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 460/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 460: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 461/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 461: ReduceLROnPlateau reducing learning rate to 1.004524037284682e-07.\n",
            "\n",
            "Epoch 461: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.3394e-07\n",
            "Epoch 462/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 462: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 463/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 463: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 464/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 464: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 465/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 465: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 466/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 466: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 467/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 467: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 468/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 468: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 469/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 469: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 470/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 470: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 471/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 471: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 472/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 472: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 473/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 473: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 473: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0045e-07\n",
            "Epoch 474/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 474: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 475/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 475: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 476/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 476: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 477/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 477: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 478/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 478: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 479/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 479: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 480/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 480: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 481/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 481: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 482/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 482: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 483/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 483: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 484/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 484: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 485/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 485: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 486/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 486: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 487/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 487: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 488/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 488: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 489/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 489: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 490/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 490: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 491/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 491: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 492/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 492: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 493/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 493: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 494/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 494: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 495/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 495: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 496/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 496: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 497/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 497: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 498/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 498: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 499/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 499: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 500/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 500: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 501/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 501: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 502/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 502: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 503/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 503: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 504/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 504: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 505/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 505: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 506/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 506: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 507/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 507: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 508/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 508: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 509/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 509: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 510/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 510: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 511/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 511: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 512/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 512: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 513/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 513: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 514/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 514: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 515/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 515: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 516/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 516: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 517/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 517: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 518/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 518: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 519/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 519: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 520/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 520: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 521/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 521: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 522/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 522: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 523/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 523: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 524/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 524: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 525/600\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 525: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 526/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 526: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 527/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 527: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 528/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 528: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 529/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 529: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 530/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 530: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 531/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 531: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 532/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 532: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 533/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 533: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 534/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 534: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 535/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 535: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 536/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 536: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 537/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 537: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 538/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 538: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 539/600\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 539: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 540/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 540: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 541/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 541: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 542/600\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 542: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 543/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 543: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 544/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 544: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 545/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 545: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 546/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 546: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 547/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 547: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 548/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 548: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 549/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 549: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 550/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 550: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 551/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 551: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 552/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 552: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 553/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 553: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 554/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 554: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 555/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 555: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 556/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 556: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 557/600\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0713\n",
            "Epoch 557: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 558/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 558: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 559/600\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 559: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 560/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 560: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 561/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 561: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 562/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 562: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 563/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 563: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 564/600\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 564: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 565/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 565: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 566/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 566: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 567/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 567: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 568/600\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 568: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 569/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 569: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 570/600\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 570: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 571/600\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 571: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 572/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0714\n",
            "Epoch 572: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 573/600\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 573: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 574/600\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 574: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 575/600\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0713\n",
            "Epoch 575: saving model to E:\\Deap learning Courses\\Level3 (Deep Learning)\\DAY8 (CNN Transfer Learning)\\model.h5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0713 - val_loss: 0.0750 - lr: 1.0000e-07\n",
            "Epoch 575: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad806069d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "auto_encoder.fit(X_train, X_train, epochs=600,\n",
        "                validation_data=(X_test, X_test), \n",
        "                shuffle=True, batch_size=64,  \n",
        "                callbacks = [red_lr ,ch_point ,ear_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7adFsZ2pWeb5",
      "metadata": {
        "id": "7adFsZ2pWeb5"
      },
      "outputs": [],
      "source": [
        "save_model(auto_encoder, \"full_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4c8374e5",
      "metadata": {
        "id": "4c8374e5"
      },
      "outputs": [],
      "source": [
        "# auto_encoder.predict(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dNbkLGnFa18w",
      "metadata": {
        "id": "dNbkLGnFa18w"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "eN2Be-g-NAUY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN2Be-g-NAUY",
        "outputId": "7e15fc6d-5cb7-4bc7-eb9c-5309606d7c56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ppLDTGWkNUSc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppLDTGWkNUSc",
        "outputId": "bcdaee8e-04d2-4ac3-d6da-fc02a47dd570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "encoder = Model(input_img, mid_layer)\n",
        "save_model(encoder, \"encoder.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cpW-DgUWPUcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpW-DgUWPUcb",
        "outputId": "68f150cc-1187-403b-a0b0-2419f7fd62a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "decoder = Model(mid_layer, output_layer4)\n",
        "save_model(decoder, \"decoder.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "tc04JCJ-Pc_o",
      "metadata": {
        "id": "tc04JCJ-Pc_o"
      },
      "outputs": [],
      "source": [
        "def show_encoding_img(X_test, n):\n",
        "    img = encoder.predict(X_test)\n",
        "    a = np.array([0, 0, 0, 0])\n",
        "\n",
        "    new_img = np.concatenate([img[n], a])\n",
        "    return px.imshow(new_img.reshape(6, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "PWbKy1TAV5rY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "PWbKy1TAV5rY",
        "outputId": "a12475ae-d3ea-4fbf-a2e8-ee2ba61d70e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"5c4f9364-9c0c-48f8-92db-e6ba0cc521af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5c4f9364-9c0c-48f8-92db-e6ba0cc521af\")) {                    Plotly.newPlot(                        \"5c4f9364-9c0c-48f8-92db-e6ba0cc521af\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[4.557927131652832,5.055286407470703,2.5372891426086426,1.6807653903961182,0.0,0.0],[5.8052496910095215,0.0,3.22700572013855,0.0,1.1489330530166626,0.0],[0.0,2.839118242263794,3.2677175998687744,0.8863670825958252,2.4660818576812744,0.0],[7.436268329620361,2.4586358070373535,2.6817262172698975,3.9731428623199463,3.0685176849365234,5.935412883758545],[2.792633295059204,3.734337329864502,4.42039680480957,4.531702995300293,3.1166634559631348,2.003730297088623],[3.4319770336151123,4.278376579284668,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5c4f9364-9c0c-48f8-92db-e6ba0cc521af');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_encoding_img(X_test, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "DuOHRVAHPsLC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "DuOHRVAHPsLC",
        "outputId": "321db2e8-1450-400e-c032-171d92fe00b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f2a612fe-f033-47d4-9cf4-4599b0656f57\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f2a612fe-f033-47d4-9cf4-4599b0656f57\")) {                    Plotly.newPlot(                        \"f2a612fe-f033-47d4-9cf4-4599b0656f57\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[1.4919778953959018e-11,9.802076685050398e-12,5.708402067011731e-12,7.934482064431148e-12,4.329292566801479e-12,6.224723427677992e-12,6.6841298121400605e-12,1.1057807447478751e-11,6.3139632411335356e-12,8.082292647648703e-12,1.0706010730721083e-11,1.4482663332482382e-11,4.1889445306199987e-16,2.214515657464748e-20,3.232668155971535e-18,6.587389460950208e-14,1.2665005329204337e-11,6.41735839815305e-12,1.4016877936118277e-11,1.5509531159363377e-11,5.468084752352498e-12,1.333032902811615e-11,2.8600977489134927e-11,8.765282770439864e-12,1.742799134174522e-11,1.3445235376441378e-11,1.9500191392185506e-11,1.3711673289840132e-11],[4.7653296239569265e-12,8.95087302887898e-12,6.445264894711089e-12,1.2674140383028831e-11,3.001619813163339e-14,4.7373446311616e-12,2.286071451498145e-13,2.720061995737863e-14,5.173358673895857e-19,8.975758637239211e-21,1.1319342252050047e-23,3.580126972265508e-30,3.9374596812749384e-32,2.0794324309420597e-35,1.5585083173494147e-38,5.885976058892744e-28,2.5159439138243516e-25,3.718575906973153e-27,1.9331911140515872e-30,4.019297541837576e-27,1.254569928776792e-27,3.97651763035488e-28,4.331046298571174e-22,4.241250138601932e-16,8.769480801251728e-12,4.105276014965131e-12,8.195771318553202e-12,6.912161815142426e-12],[6.7491320691892565e-12,6.42001469347564e-12,5.025168212501701e-17,1.235661014698311e-13,1.3993890952707783e-13,1.7693444907991573e-13,1.5594329213358682e-12,4.894179133245805e-16,1.5383518583818782e-19,7.979542626476755e-23,1.1904766973867233e-24,3.665467351529847e-34,0.0,0.0,0.0,5.63336898752054e-35,1.0021591873058537e-27,1.4008431066037366e-30,1.5920950256169856e-28,1.2108474864386125e-26,8.346456578691554e-31,0.0,0.0,1.1856683719780895e-31,6.436683932095295e-25,2.233434667478771e-20,1.067178029973137e-11,1.9369190279450166e-11],[4.823507045170761e-12,1.6912743774910588e-11,2.3321741806991053e-24,6.511825487649207e-21,1.036969121681608e-12,3.5731512470938773e-17,1.962231231653392e-18,2.2309077664167407e-18,1.051749485986091e-19,3.318490924045926e-27,4.318016787338819e-28,1.978451215652968e-33,0.0,0.0,0.0,0.0,6.01884202994454e-38,0.0,0.0,6.682881453209002e-34,2.566703905062843e-31,4.235489817005018e-33,0.0,0.0,1.6764237996164944e-37,7.364079720740321e-27,1.5110186335355982e-16,1.0856927336322375e-11],[1.1075433972718152e-11,1.0979323055099535e-13,2.320670548755986e-26,7.181564804642493e-12,4.3803584891255465e-12,3.657359517236086e-15,2.1786254915455265e-15,1.6742098374945715e-18,1.581381761535144e-20,4.745637368459934e-27,6.2245087195250385e-31,3.262479991242347e-37,0.0,0.0,0.0,0.0,1.256221159903027e-36,0.0,4.040775147098556e-34,0.0,4.231853590534642e-34,8.570381944572557e-36,0.0,0.0,2.3096456885841528e-36,1.130206777917928e-33,4.8504846575946345e-30,8.396021813179225e-15],[4.049052326066116e-12,1.418251020096628e-11,6.640621467212192e-19,1.5644222584043632e-09,1.4527536507102923e-07,2.7902798294121567e-08,4.086425775540192e-08,1.3847309965342447e-08,5.44178813122187e-10,1.7726296125397667e-11,6.245447952205052e-13,6.699559980100198e-16,4.88349631900576e-22,4.561416660583721e-19,4.1944963691435894e-22,8.167690420480133e-21,1.134337568838851e-23,1.7836100221467395e-31,2.1663016278121107e-38,7.689863063916775e-35,3.390889308901771e-30,8.647872210498935e-17,5.214007190953475e-14,1.4988146357711174e-15,1.4212378527474114e-15,3.1586419762440416e-16,6.044987852820293e-21,1.16610475615897e-12],[1.6833732324750272e-11,5.462135257983114e-11,1.501763790656696e-06,2.9124996103746525e-07,0.00010144393309019506,0.0010288433404639363,0.0025520785711705685,0.0015752892941236496,0.0006495799752883613,7.504362292820588e-05,2.0118217435083352e-05,3.7906859233771684e-06,3.489380731025449e-07,2.2602226756873733e-09,7.878714174125445e-12,1.574643988533353e-07,1.7286841114128038e-07,8.564049380765937e-08,1.9170563803072582e-08,4.7975131423072526e-08,2.638233631557796e-08,9.279057877620289e-08,1.275179499771184e-07,9.30924226594243e-09,3.662049152808322e-08,1.7830688037179243e-09,8.594756017998861e-10,1.170515906423475e-10],[5.863216023804796e-10,4.161320177331618e-08,4.8460815804673985e-08,3.816043317783624e-06,0.0008456490468233824,0.11286408454179764,0.6046237349510193,0.7980062961578369,0.7274792194366455,0.5552516579627991,0.26918840408325195,0.0829722136259079,0.024505794048309326,0.014571433886885643,0.014153690077364445,0.0050087557174265385,0.0015868351329118013,0.002741257194429636,0.0043333470821380615,0.004579729866236448,0.001996638486161828,0.00039390119491145015,4.5251257688505575e-05,2.7979065180261387e-06,1.2191525229354738e-06,2.1050779253073415e-07,6.635273385423301e-13,7.139475122208694e-11],[4.964195027268303e-11,2.040120818946889e-07,3.32475315190095e-06,1.1754540537367575e-05,0.0007174138445407152,0.133599653840065,0.7751560211181641,0.9523237943649292,0.9555711150169373,0.921629786491394,0.886428713798523,0.8781641125679016,0.8859333395957947,0.9073588848114014,0.8926898241043091,0.8742614984512329,0.8864848017692566,0.8248637914657593,0.8179810047149658,0.8167732954025269,0.6527952551841736,0.152021124958992,0.002482420764863491,3.255183037254028e-05,3.4049471651087515e-06,3.336356968475229e-08,2.9857121956007246e-14,4.698237119139836e-16],[3.946478273064713e-07,3.118231859389198e-07,2.3394732124870643e-05,5.453292033053003e-06,4.93804836878553e-05,0.004759333562105894,0.1620965301990509,0.5075162053108215,0.45902207493782043,0.4736066460609436,0.6995137333869934,0.8789891004562378,0.9465892910957336,0.9740632176399231,0.9726322889328003,0.9722951650619507,0.9688113331794739,0.9410908222198486,0.9464712738990784,0.9758409857749939,0.9800634384155273,0.6531237363815308,0.0073409778997302055,3.4748456528177485e-05,3.365407110322849e-06,2.6270148278939587e-09,2.3059090986481123e-13,1.3190406883065164e-12],[1.5243413145071827e-06,3.1718070658826036e-07,4.787591478816466e-06,1.832975840443396e-06,2.68573421635665e-06,5.3443956858245656e-05,0.001715263701044023,0.003966101445257664,0.0043199434876441956,0.008884996175765991,0.028303416445851326,0.05305125191807747,0.1147272139787674,0.17954878509044647,0.1855909526348114,0.15969319641590118,0.12354260683059692,0.10647527873516083,0.44997385144233704,0.9470375776290894,0.9719862937927246,0.39042574167251587,0.0016320757567882538,6.821887382102432e-06,2.3447719854630122e-07,2.2502473218111163e-09,3.409737076021102e-11,1.3390931904457525e-14],[1.056593461612465e-07,7.894522582319041e-07,5.654395408782875e-06,1.1385822062948137e-07,8.647663207739242e-08,9.020583320307196e-07,1.3160210983187426e-05,3.783834108617157e-05,4.082117084180936e-05,0.00012435170356184244,0.00015456102846655995,8.472495392197743e-05,8.053579222178087e-05,0.00029446594999171793,0.0004054526216350496,0.0004880284541286528,0.0007849467801861465,0.0053265150636434555,0.29673561453819275,0.9349838495254517,0.8272578716278076,0.031023427844047546,4.015131708001718e-05,3.460318112047389e-07,4.327159217609733e-07,6.359783810694353e-08,4.55464523518509e-15,5.84604339268136e-17],[1.9974849899129232e-11,6.200896046637538e-11,1.0499540081809755e-07,3.4582356533974234e-08,6.005620178939353e-08,8.806424034446536e-08,4.2917699261124653e-07,8.320341748913052e-07,1.2201296613056911e-06,2.838503121438407e-07,1.08810854726471e-06,3.0566019404432154e-07,3.6265794278733665e-07,5.668172207151656e-07,8.094848453765735e-06,3.2700958399800584e-05,0.0004926904803141952,0.03491026535630226,0.7830248475074768,0.9417523145675659,0.35848933458328247,0.0016151792369782925,1.6378171494579874e-06,2.5579810269960035e-08,2.93120251626533e-07,2.360676931711936e-10,1.3302583615201822e-16,6.110181236537479e-21],[4.6006516603086176e-14,1.2915958233494784e-11,4.694307442765222e-11,2.533620882538834e-11,7.60067919713947e-09,2.4035324841520378e-08,6.953490583327948e-07,2.434550651742029e-06,2.125439202416146e-08,3.329504636440106e-07,5.062411290168711e-08,1.2737168653131903e-08,5.244502787604688e-08,1.6333422081515891e-07,2.887043365262798e-06,0.00010253453365294263,0.00718318996950984,0.45749545097351074,0.9537689685821533,0.8152077794075012,0.03451007977128029,4.0748127503320575e-05,1.3373889373724523e-07,1.2705505092469593e-08,4.908357027488819e-07,2.8934059592700123e-09,3.5014576008884975e-19,3.4648951424788574e-17],[1.476421632520819e-12,3.231395619834876e-12,1.327676996121241e-10,1.2035359375772714e-09,7.554040060142597e-09,3.237504131448077e-07,1.0477752709903143e-07,1.8478820251743855e-08,3.7700417787611684e-10,1.2718105457665274e-09,2.0067254524747113e-08,3.050431907070106e-09,1.3487817085433562e-08,1.1327995963483772e-07,9.884824976325035e-06,0.0006990309921093285,0.09759202599525452,0.8815324306488037,0.9277520775794983,0.2691393494606018,0.0008662900654599071,1.3407428696154966e-06,2.2326332782540703e-07,2.3384677660942543e-07,2.086278072965797e-06,4.846717249762378e-09,4.865106898454227e-22,8.819685035264487e-16],[7.974403082311454e-11,4.844803486343807e-13,3.3166086543801043e-10,6.452500339593215e-11,1.27658605908465e-09,9.853457072495075e-08,2.052750858183572e-08,1.1171026770284698e-08,2.5267093306524657e-08,7.221880338192932e-08,1.5877080983273117e-08,8.631987569174271e-09,1.88550739466109e-08,5.498771429301996e-07,5.429966768133454e-05,0.005988919176161289,0.578256368637085,0.9556101560592651,0.7417012453079224,0.019887585192918777,2.8999938876950182e-05,3.141178410714929e-07,4.541743692243472e-08,3.541988746746938e-07,3.158559525040516e-11,2.946168309314601e-11,8.176487265032506e-12,1.5255435611325598e-17],[1.1357771277295536e-12,5.533254639339538e-17,2.1216071434404515e-12,2.4644606355650467e-09,1.579094721648744e-08,1.4338922937895404e-07,6.06655774504361e-08,3.416558058688679e-08,1.0823325347075752e-08,1.5527839014595202e-09,2.2772297825213172e-08,8.22127166344444e-09,5.923245538497213e-08,1.148181218013633e-05,0.00046817411202937365,0.09516063332557678,0.9129506945610046,0.9421064257621765,0.2160886973142624,0.0011028253939002752,2.5932906737580197e-06,1.8086676334405638e-07,3.7979752676164935e-09,2.2105750119294498e-08,3.6373543066403613e-10,7.964560543201327e-13,8.818710518776474e-12,4.1731168845481334e-19],[7.189609584762335e-12,2.1699732088080014e-16,2.5010280305104438e-12,6.754576897805009e-09,2.988603853282257e-08,1.2687145272138878e-06,1.466006125383501e-07,1.178343733698739e-08,2.2764861107305023e-09,1.5129072439279412e-09,1.85613430403464e-07,1.64161875204627e-07,2.546423047533608e-06,8.86872221599333e-05,0.01081177033483982,0.677745521068573,0.9632819294929504,0.6872820854187012,0.01917506940662861,0.00012634113954845816,8.272717764157278e-07,1.0218299451025814e-07,7.281989677920819e-09,4.120022101261611e-09,2.1940489425276155e-09,2.767469864384253e-10,1.0312048456351079e-14,2.8754182991212003e-15],[7.663256964760001e-13,3.880250731591898e-15,1.5633634387057782e-09,1.3035210599809943e-07,5.623274432764447e-07,6.232213536350173e-07,1.9000570716798393e-07,2.447858138410197e-09,1.1056411786114495e-08,1.5688515375700263e-08,1.3931949069956318e-06,2.5721651581989136e-06,2.486256926204078e-05,0.0026907543651759624,0.3113510012626648,0.9528697729110718,0.8896071910858154,0.13148251175880432,0.0011900454992428422,0.00023392964794766158,3.8702969504811335e-06,1.5101554708962794e-06,1.6074194419957166e-08,6.630969107135343e-10,2.1835625755445287e-12,2.469045454200902e-11,1.0597894632181915e-13,7.252534618869266e-13],[1.698448273571105e-14,2.565645615959511e-07,8.290907089758548e-07,7.970976980686828e-07,6.66664874415801e-08,4.6736558942939155e-06,4.380285645311233e-06,2.5019669465109473e-06,7.2979804421891e-09,1.202615607098778e-07,3.240044634367223e-06,5.547140517592197e-06,0.00033677133615128696,0.07287400960922241,0.8750466704368591,0.9521195888519287,0.3972266614437103,0.004023800138384104,5.8972051192540675e-05,7.154675404308364e-05,5.720436092815362e-06,1.0838906661092551e-07,6.290480882853444e-07,5.227771993077113e-09,7.673499169413844e-08,6.039218902742505e-08,2.0440647524905398e-20,4.605743305056483e-18],[2.4603988551391565e-12,1.5123256957849662e-07,2.5160629775200505e-06,2.0666743694164325e-07,7.242073962743234e-08,6.364773980749305e-06,2.8625227059819736e-06,3.507981816142092e-08,7.825036618669401e-09,9.356067494081799e-07,1.5256213373504579e-05,0.00010373503755545244,0.01912236213684082,0.6551938652992249,0.9671042561531067,0.8458113670349121,0.0519629567861557,0.0004413791175466031,9.092788786801975e-06,1.9960928909767972e-07,9.85896075889059e-09,3.670174564263107e-08,2.9516229460568866e-06,1.5750148918414197e-07,1.0515246913200826e-06,5.036982386741329e-09,1.0818403618103381e-21,2.477603896784003e-14],[1.0905662698314049e-14,1.7186878717358623e-15,8.871106516039617e-09,3.28317213416085e-08,1.658465521359176e-06,4.881486802332802e-06,2.485147433617385e-06,6.277527386799875e-09,4.557248800551861e-09,9.574538495371598e-08,9.368405881104991e-05,0.003910304047167301,0.3572050929069519,0.9535894393920898,0.9520198702812195,0.3653409481048584,0.006708948407322168,3.864333848468959e-05,1.7143057675639284e-06,3.451481234151288e-08,1.4612494396715192e-06,2.85574174085923e-07,1.6944509795280283e-08,3.0155166541590006e-07,5.137701009516604e-06,1.927093901121779e-12,3.74071065887261e-21,1.2251689689878113e-16],[8.958750692786462e-15,1.6589615792206303e-10,5.281763524808691e-13,8.874304846528958e-09,6.04681460458778e-08,5.261711635284883e-07,1.1879277117543552e-08,4.706489065142705e-08,3.2637771596455423e-07,6.681072136416333e-06,0.0014166751643642783,0.09128230810165405,0.874477744102478,0.9683920741081238,0.6973752975463867,0.042131878435611725,0.0011684736236929893,4.172538319835439e-05,5.3116827984922566e-06,7.563342308003485e-08,5.530046109925024e-07,4.6044760892982595e-07,1.3126618796377443e-06,5.935177327387464e-08,2.20914580495446e-06,8.387448513502704e-10,1.1812114331838859e-18,3.4662834824189664e-17],[1.9069589657361163e-11,1.1902074811831476e-11,1.7264533173303592e-13,4.3297593288471603e-10,5.0764772332816303e-17,2.664334863844431e-10,2.0422425903166008e-11,1.2925959858023361e-08,5.951023496209018e-08,8.038617670536041e-05,0.016553813591599464,0.6103339195251465,0.982455849647522,0.9346821904182434,0.31237924098968506,0.007332750130444765,0.0004941922961734235,2.2396274289349094e-05,1.5216339477319707e-07,1.5383017526460208e-08,4.5739152483292855e-06,9.216703489300926e-08,2.4400792497658585e-08,2.801975362842768e-08,9.729300245453487e-07,1.711362496159552e-09,3.300578857081526e-18,6.510588942965079e-12],[6.607075997422385e-12,9.092349269324007e-12,3.113617491005277e-13,6.089324092975901e-16,1.3094311130724436e-14,4.9194433520294983e-14,5.591654967014321e-15,2.0739551569171066e-12,9.05944119722335e-08,0.00016355638217646629,0.10849311947822571,0.9538446664810181,0.9961413741111755,0.9037919044494629,0.12891513109207153,0.0015209914417937398,3.569163163774647e-05,2.275850420119241e-06,2.833377550359728e-07,4.528053068497684e-06,1.2530354069895111e-05,2.3337051970884204e-06,4.35976197366017e-08,5.835194549774769e-09,1.0404551176179666e-06,4.136559150769159e-12,7.629511629539181e-16,7.847503896707408e-12],[7.975768483159396e-12,1.8574589782938133e-11,2.9210092122866627e-09,1.3132838150298198e-09,1.7937504492138807e-15,7.24763697374172e-21,1.4114794402719788e-12,1.0968099345420868e-10,3.416695619762322e-07,0.0004187082522548735,0.24077282845973969,0.9908576607704163,0.9909318685531616,0.7187868356704712,0.01901107281446457,0.0002185579651268199,2.4395161744905636e-05,3.5854639008903177e-06,3.121932579119857e-08,7.463557381015562e-07,5.258689725451404e-06,2.6175930756267007e-08,2.585089475815039e-08,2.628948447824797e-10,4.252380492175689e-08,1.4375240364392083e-12,1.9693739640360558e-14,5.094162505020483e-12],[3.967292206558115e-12,6.837433397244297e-12,3.938408627002232e-12,9.540789382492254e-13,1.568941851437522e-11,4.3352742368185074e-16,1.1731873881658944e-13,1.8064663098726896e-09,2.2132894628157374e-06,0.0002446959260851145,0.12996725738048553,0.9665212631225586,0.8847157955169678,0.12611497938632965,0.00215684506110847,6.749434396624565e-05,7.426534011756303e-06,7.813934530531697e-07,3.062005857201733e-11,5.863215593376533e-14,1.6602381691654955e-09,1.8821107516941993e-07,4.762147565173791e-09,9.555481961243117e-10,1.8750798136402125e-10,3.7264590718733004e-11,1.1152382836665531e-11,5.592655678843261e-12],[5.590138595079619e-12,1.3512102894908118e-11,1.4306620992055041e-11,1.0244449386020982e-11,1.3318427307187908e-12,4.649693715989833e-13,3.571477315278404e-12,2.0608825757051363e-09,4.942451337086595e-09,2.2219841966375498e-08,7.013331924099475e-05,0.0006090547540225089,0.000803729344625026,3.9240218029590324e-05,2.144148538718582e-06,6.6170877666138495e-09,7.471324253716105e-11,4.186904434266836e-10,2.9577235105548993e-10,4.5170204382438683e-11,3.266074077856729e-10,2.8951657737863457e-10,3.569044837448132e-09,3.3848062130914514e-09,7.77396983592249e-12,1.4571356274362124e-11,1.3065291903924248e-11,1.260918366247088e-11]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f2a612fe-f033-47d4-9cf4-4599b0656f57');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "img = decoder.predict(encoder.predict(X_test))\n",
        "\n",
        "px.imshow(img[0].reshape(28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d21MWQq_bVzv",
      "metadata": {
        "id": "d21MWQq_bVzv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}